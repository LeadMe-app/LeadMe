# -*- coding: utf-8 -*-
from fastapi import APIRouter, Depends, HTTPException, status, File, UploadFile, BackgroundTasks
from sqlalchemy.orm import Session
from typing import List, Optional
import os
import tempfile
import shutil
import librosa
from pydub import AudioSegment
from datetime import datetime, date
import logging
import subprocess

# ë‚´ë¶€ ëª¨ë“ˆ ì„í¬íŠ¸
from database import get_db
import models
from schemas.speech import SpeedAnalysisCreate, SpeedAnalysisResponse
from schemas.user import UserSettingsCreate, UserSettingsResponse
from app.api.auth import get_current_user
from services.openai_stt import OpenAISTTService
#from services.naver_clova import NaverClovaService


print(f"ğŸ” DEBUG: íŒŒì¼ëª…={file.filename}")
print(f"ğŸ” DEBUG: ì‚¬ìš©ì={current_user.user_id if current_user else 'None'}")
print(f"ğŸ” DEBUG: íŒŒì¼ í¬ê¸°={file.size if hasattr(file, 'size') else 'unknown'}")

router = APIRouter()
logger = logging.getLogger(__name__)

# ë¡œê·¸ ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger("speed_analysis")

# ì—…ë¡œë“œ ë””ë ‰í† ë¦¬ ì„¤ì •
UPLOAD_DIR = "uploads/audio"
os.makedirs(UPLOAD_DIR, exist_ok=True)

# openai whisper ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
OpenAI_Whisper = OpenAISTTService()

def convert_m4a_to_wav(input_path: str, output_path: str):
    command = [
        "ffmpeg",
        "-y",
        "-i", input_path,
        "-ac", "1",            # mono
        "-ar", "16000",        # 16kHz
        "-sample_fmt", "s16",  # 16-bit PCM
        output_path,
    ]
    subprocess.run(command, check=True)

def inspect_audio_file(path: str):
    command = ["ffmpeg", "-v", "error", "-i", path, "-f", "null", "-"]
    result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)

    if result.returncode == 0:
        print("ì˜¤ë””ì˜¤ íŒŒì¼ì€ ë¬¸ì œ ì—†ìŠµë‹ˆë‹¤.")
    else:
        print("ì˜¤ë””ì˜¤ íŒŒì¼ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
        print(result.stderr.decode("utf-8", errors="ignore"))


@router.post("/analyze-audio-file/", status_code=status.HTTP_201_CREATED)
async def analyze_audio_file(
        file: UploadFile = File(...),
        background_tasks: BackgroundTasks = None,
        db: Session = Depends(get_db),
        current_user: models.User = Depends(get_current_user)  # í˜„ì¬ ë¡œê·¸ì¸í•œ ì‚¬ìš©ì ê°€ì ¸ì˜¤ê¸°
):
    """
    ìŒì„± íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ë°œí™” ì†ë„ë¥¼ ì¸¡ì •í•˜ê³  ê²°ê³¼ë¥¼ DBì— ì €ì¥í•©ë‹ˆë‹¤.
    í˜„ì¬ ë¡œê·¸ì¸í•œ ì‚¬ìš©ìì˜ IDê°€ ìë™ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
    ë„¤ì´ë²„ í´ë¡œë°” STTë¥¼ í™œìš©í•˜ì—¬ ë” ì •í™•í•œ ìŒì ˆ ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

    Args:
        file: ë¶„ì„í•  ìŒì„± íŒŒì¼
        background_tasks: ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        current_user: í˜„ì¬ ë¡œê·¸ì¸í•œ ì‚¬ìš©ì

    Returns:
        ë¶„ì„ ê²°ê³¼
    """
    print("íŒŒì¼ ì´ë¦„:", file.filename)  # <- ì¶”ê°€

    # íŒŒì¼ í™•ì¥ì ê²€ì¦
    if not file.filename.lower().endswith(('.wav', '.mp3', '.m4a', '.ogg')):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. .wav, .mp3, .m4a, .ogg í˜•ì‹ë§Œ í—ˆìš©ë©ë‹ˆë‹¤."
        )

    try:
        original_ext = os.path.splitext(file.filename)[1].lower()
        is_convert_needed = original_ext != ".wav"

        # 1. ì›ë³¸ ì„ì‹œ íŒŒì¼ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix=original_ext) as temp_file:
            temp_file_path = temp_file.name
            shutil.copyfileobj(file.file, temp_file)

        logger.info(f"ì„ì‹œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {temp_file_path}")

        # 2. ë³€í™˜ í•„ìš”í•˜ë©´ wavë¡œ ë³€í™˜
        if is_convert_needed:
            wav_temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
            wav_temp_path = wav_temp_file.name
            wav_temp_file.close()

            convert_m4a_to_wav(temp_file_path, wav_temp_path)
            inspect_audio_file(wav_temp_path)  # ë³€í™˜ í›„ ìœ íš¨ì„± ê²€ì‚¬
            used_audio_path = wav_temp_path
        else:
            used_audio_path = temp_file_path

        user_id = current_user.user_id

        db_age_group_speed = db.query(models.AgeGroupSpeechRate).filter(
            models.AgeGroupSpeechRate.age_group == current_user.age_group
        ).first()

        # ì˜¤ë””ì˜¤ ë¶„ì„
        y, sr = librosa.load(used_audio_path, sr=None)
        duration = librosa.get_duration(y=y, sr=sr)

        frames = librosa.effects.split(y, top_db=20)
        voiced_duration = sum(f[1] - f[0] for f in frames) / sr
        voiced_percentage = voiced_duration / duration * 100

        logger.info("Whisper STT í˜¸ì¶œ ì‹œì‘")
        stt_result = OpenAI_Whisper.speech_to_text(used_audio_path)
        logger.info(f"STT ê²°ê³¼: {stt_result}")

        if stt_result["status"] == "success":
            text = stt_result["text"]
            syllables_count = OpenAI_Whisper.count_korean_syllables(text)
            logger.info(f"STT ì„±ê³µ - í…ìŠ¤íŠ¸: '{text}', ìŒì ˆ ìˆ˜: {syllables_count}")
        else:
            syllables_count = int(voiced_duration * 4.5)
            logger.warning(f"STT ì‹¤íŒ¨ - ì¶”ì • ìŒì ˆ ìˆ˜: {syllables_count}")

        spm = int(syllables_count / duration * 60)
        logger.info(f"ë¶„ì„ ê²°ê³¼: ìŒì ˆ ìˆ˜={syllables_count}, ë…¹ìŒ ê¸¸ì´={duration:.2f}ì´ˆ, SPM={spm}")

        speed_category = "ì •ìƒ"
        if db_age_group_speed:
            if spm <= db_age_group_speed.slow_rate:
                speed_category = "ëŠë¦¼"
            elif spm >= db_age_group_speed.fast_rate:
                speed_category = "ë¹ ë¦„"
        else:
            if spm < 180:
                speed_category = "ëŠë¦¼"
            elif spm > 300:
                speed_category = "ë¹ ë¦„"

        db_analysis = models.SpeedAnalysis(
            user_id=user_id,
            spm=spm,
            speed_category=speed_category,
            analysis_date=datetime.utcnow().date()
        )

        db.add(db_analysis)
        db.commit()
        db.refresh(db_analysis)
        logger.info(f"ë¶„ì„ ê²°ê³¼ DB ì €ì¥ ì™„ë£Œ (ID: {db_analysis.analysis_id})")

        analysis_result = {
            "status": "success",
            "duration": round(duration, 2),
            "voiced_duration": round(voiced_duration, 2),
            "voiced_percentage": round(voiced_percentage, 1),
            "syllables_estimate": syllables_count,
            "spm": spm,
            "speed_category": speed_category,
            "db_analysis_id": db_analysis.analysis_id,
            "user_id": user_id
        }

        if stt_result["status"] == "success":
            analysis_result["stt_text"] = stt_result["text"]
            analysis_result["stt_confidence"] = stt_result.get("confidence", 0)

        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        permanent_filename = f"speech_{user_id}_{timestamp}{original_ext}"
        permanent_path = os.path.join(UPLOAD_DIR, permanent_filename)

        shutil.copy2(temp_file_path, permanent_path)

        if background_tasks:
            background_tasks.add_task(os.remove, temp_file_path)
            if is_convert_needed:
                background_tasks.add_task(os.remove, wav_temp_path)
        else:
            os.remove(temp_file_path)
            if is_convert_needed:
                os.remove(wav_temp_path)

        analysis_result["file_path"] = permanent_path
        analysis_result["file_url"] = f"/uploads/audio/{permanent_filename}"

        return analysis_result

    except Exception as e:
        if 'temp_file_path' in locals() and os.path.exists(temp_file_path):
            os.remove(temp_file_path)
        if 'wav_temp_path' in locals() and os.path.exists(wav_temp_path):
            os.remove(wav_temp_path)

        logger.error(f"ìŒì„± ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ìŒì„± ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


@router.post("/record-audio/", status_code=status.HTTP_201_CREATED)
async def record_and_analyze_audio(
        duration: int = 10,
        user_id: Optional[str] = None,
        db: Session = Depends(get_db)
):
    """
    ë§ˆì´í¬ë¡œ ìŒì„±ì„ ë…¹ìŒí•˜ê³  ë°œí™” ì†ë„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.

    Args:
        duration: ë…¹ìŒ ì‹œê°„(ì´ˆ)
        user_id: ì‚¬ìš©ì ID (ì„ íƒ ì‚¬í•­)
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜

    Returns:
        ë…¹ìŒ ë° ë¶„ì„ ê²°ê³¼
    """
    # ì—¬ê¸°ì— ë…¹ìŒ ê¸°ëŠ¥ êµ¬í˜„ í•„ìš”
    # ì´ ë¶€ë¶„ì€ í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œì—ì„œ ì²˜ë¦¬ë˜ë¯€ë¡œ, API ì¸¡ì—ì„œëŠ” ë¶„ì„ë§Œ ë‹´ë‹¹

    raise HTTPException(
        status_code=status.HTTP_501_NOT_IMPLEMENTED,
        detail="í˜„ì¬ ì„œë²„ì—ì„œ ì§ì ‘ ë…¹ìŒì€ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í´ë¼ì´ì–¸íŠ¸ì—ì„œ ë…¹ìŒ í›„ ë¶„ì„ APIë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”."
    )


@router.post("/analyze-audio/", status_code=status.HTTP_201_CREATED)
async def analyze_uploaded_audio(
        file: UploadFile = File(...),
        user_id: Optional[str] = None,
        db: Session = Depends(get_db)
):
    """
    ì—…ë¡œë“œëœ ìŒì„± íŒŒì¼ì„ ë¶„ì„í•©ë‹ˆë‹¤. (ë¡œê·¸ì¸ ë¶ˆí•„ìš”)

    Args:
        file: ë¶„ì„í•  ìŒì„± íŒŒì¼
        user_id: ì‚¬ìš©ì ID (ì„ íƒ ì‚¬í•­)
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜

    Returns:
        ë¶„ì„ ê²°ê³¼
    """
    # íŒŒì¼ í™•ì¥ì ê²€ì¦
    if not file.filename.lower().endswith(('.wav', '.mp3', '.m4a', '.ogg')):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. .wav, .mp3, .m4a, .ogg í˜•ì‹ë§Œ í—ˆìš©ë©ë‹ˆë‹¤."
        )

    try:
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(file.filename)[1]) as temp_file:
            temp_file_path = temp_file.name
            shutil.copyfileobj(file.file, temp_file)

        # ì‚¬ìš©ì IDê°€ ì œê³µëœ ê²½ìš° í•´ë‹¹ ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ
        age_group = "14ì„¸ ì´ìƒ"  # ê¸°ë³¸ê°’
        if user_id:
            db_user = db.query(models.User).filter(models.User.user_id == user_id).first()
            if db_user:
                age_group = db_user.age_group

        # ===== STT ë° ìŒì ˆ ìˆ˜ ê³„ì‚° ì‹œì‘ =====
        # 1. ì˜¤ë””ì˜¤ ê¸°ë³¸ ë¶„ì„
        y, sr = librosa.load(temp_file_path, sr=None)
        duration = librosa.get_duration(y=y, sr=sr)

        # ìŒì„± í™œì„±í™” ê²€ì¶œ
        frames = librosa.effects.split(y, top_db=20)
        voiced_duration = sum(f[1] - f[0] for f in frames) / sr
        voiced_percentage = voiced_duration / duration * 100

        # 2. ë„¤ì´ë²„ í´ë¡œë°” STTë¡œ í…ìŠ¤íŠ¸ ë³€í™˜
        stt_result = OpenAI_Whisper.speech_to_text(temp_file_path)

        # ìŒì ˆ ìˆ˜ ê³„ì‚° (STT ì„±ê³µ ì‹œ í…ìŠ¤íŠ¸ ê¸°ë°˜, ì‹¤íŒ¨ ì‹œ ì¶”ì •)
        if stt_result["status"] == "success":
            text = stt_result["text"]
            syllables_count = OpenAI_Whisper.count_korean_syllables(text)
        else:
            # STT ì‹¤íŒ¨ ì‹œ ì¶”ì •ì¹˜ ì‚¬ìš©
            syllables_count = int(voiced_duration * 4.5)  # í•œêµ­ì–´ í‰ê·  ë°œí™” ì†ë„ë¡œ ì¶”ì •

        # SPM ê³„ì‚°
        spm = int(syllables_count / duration * 60)
        # ===== STT ë° ìŒì ˆ ìˆ˜ ê³„ì‚° ì¢…ë£Œ =====

        # ì—°ë ¹ëŒ€ë³„ ë°œí™” ì†ë„ ì •ë³´ ì¡°íšŒ
        db_age_group_speed = db.query(models.AgeGroupSpeechRate).filter(
            models.AgeGroupSpeechRate.age_group == age_group
        ).first()

        # ì†ë„ ì¹´í…Œê³ ë¦¬ ê²°ì •
        speed_category = "ì •ìƒ"
        if db_age_group_speed:
            if spm <= db_age_group_speed.slow_rate:
                speed_category = "ëŠë¦¼"
            elif spm >= db_age_group_speed.fast_rate:
                speed_category = "ë¹ ë¦„"
        else:
            # ê¸°ë³¸ ê¸°ì¤€ ì ìš©
            if spm < 180:
                speed_category = "ëŠë¦¼"
            elif spm > 300:
                speed_category = "ë¹ ë¦„"

        # ì‚¬ìš©ì IDê°€ ì œê³µëœ ê²½ìš°ì—ë§Œ DBì— ì €ì¥
        db_analysis_id = None
        if user_id:
            db_analysis = models.SpeedAnalysis(
                user_id=user_id,
                spm=spm,
                speed_category=speed_category,
                analysis_date=datetime.utcnow().date()
            )

            db.add(db_analysis)
            db.commit()
            db.refresh(db_analysis)
            db_analysis_id = db_analysis.analysis_id

        # ë¶„ì„ ê²°ê³¼ êµ¬ì„±
        analysis_result = {
            "status": "success",
            "duration": round(duration, 2),
            "voiced_duration": round(voiced_duration, 2),
            "voiced_percentage": round(voiced_percentage, 1),
            "syllables_estimate": syllables_count,
            "spm": spm,
            "speed_category": speed_category
        }

        # DB ì €ì¥ ì •ë³´ ì¶”ê°€ (ì €ì¥ëœ ê²½ìš°)
        if db_analysis_id:
            analysis_result["db_analysis_id"] = db_analysis_id
            analysis_result["user_id"] = user_id

        # STT ê²°ê³¼ ì¶”ê°€ (ì„±ê³µí•œ ê²½ìš°)
        if stt_result["status"] == "success":
            analysis_result["stt_text"] = stt_result["text"]
            analysis_result["stt_confidence"] = stt_result.get("confidence", 0)

        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        os.remove(temp_file_path)

        return analysis_result

    except Exception as e:
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if 'temp_file_path' in locals() and os.path.exists(temp_file_path):
            os.remove(temp_file_path)

        logger.error(f"ìŒì„± ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ìŒì„± ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


@router.get("/analysis/", response_model=List[SpeedAnalysisResponse])
def read_speech_analyses(
        user_id: Optional[str] = None,
        skip: int = 0,
        limit: int = 100,
        db: Session = Depends(get_db)
):
    """ì‚¬ìš©ìë³„ ë°œí™” ì†ë„ ë¶„ì„ ê¸°ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
    query = db.query(models.SpeedAnalysis)

    if user_id:
        query = query.filter(models.SpeedAnalysis.user_id == user_id)

    analyses = query.order_by(models.SpeedAnalysis.analysis_date.desc()).offset(skip).limit(limit).all()
    return analyses
